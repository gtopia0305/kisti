# 가. Tensorflow에서 Horovod 사용법

다중노드에서 CPU를 활용할 경우 Horovod를 Tensorflow와 연동하여 병렬화가 가능하다. 아래 예시와 같이 Horovod 사용을 위한 코드를 추가해주면 Tensorflow와 연동이 가능하다. Tensorflow 및 Tensorflow에서 활용 가능한 Keras API 모두 Horovod와 연동이 가능하며 우선 Tensorflow에서 Horovod와 연동하는 방법을 소개한다.\
(예시: MNIST Dataset 및 LeNet-5 CNN 구조)

※ Tensorflow에서 Horovod 활용을 위한 자세한 사용법은 Horovod 공식 가이드 참조\
([https://github.com/horovod/horovod#usage](https://github.com/horovod/horovod#usage))

**◦ Tensorflow에서 Horovod 사용을 위한 import 및 메인 함수에서 Horovod 초기화**

| <p>import horovod.tensorflow as hvd</p><p>...</p><p>hvd.init()</p> |
| ------------------------------------------------------------------ |

※ horovod.tensorflow: Horovod를 Tensorflow와 연동하기 위한 모듈

※ Horovod를 사용하기 위하여 초기화한다.

**◦ 메인 함수에서 Horovod 활용을 위한 Dataset 설정**

| <p>(x_train, y_train), (x_test, y_test) = &#x3C;/p></p><p>keras.datasets.mnist.load_data('MNIST-data-%d' % hvd.rank())</p> |
| -------------------------------------------------------------------------------------------------------------------------- |

※ 각 작업별로 접근할 dataset을 설정하기 위하여 Horovod rank에 따라 설정 및 생성한다.

**◦ 메인 함수에서 optimizer에 Horovod 관련 설정 및 broadcast, 학습 진행 수 설정**

| <p>opt = tf.train.AdamOptimizer(0.001 * hvd.size())</p><p>opt = hvd.DistributedOptimizer(opt)</p><p>global_step = tf.train.get_or_create_global_step()</p><p>train_op = opt.minimize(loss, global_step=global_step)</p><p>hooks = [hvd.BroadcastGlobalVariablesHook(0),</p><p>tf.train.StopAtStepHook(last_step=20000 // hvd.size()), ... ]</p> |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |

※ Optimizer에 Horovod 관련 설정을 적용하고 각 작업에 broadcast를 활용하여 전달함

※ 각 작업들의 학습과정 step을 Horovod 작업 수에 따라 설정함

**◦ Inter operation 및 Intra operation의 병렬처리 설정**

| <p>config = tf.ConfigProto()</p><p>config.intra_op_parallelism_threads = int(os.environ[‘OMP_NUM_THREADS’])</p><p>config.inter_op_parallelism_threads = 2</p> |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------- |

※ config.intra\_op\_parallelism\_threads: 연산 작업에서 사용할 thread 개수를 설정하는데 사용되며 job script에서 설정한 OMP\_NUM\_THREADS를 불러와서 적용함 (본 예시의 경우 OMP\_NUM\_THREADS를 32로 설정함)

※ config.intra\_op\_parallelism\_threads: TensorFlow의 작업을 동시에 실행하는 thread 개수이며 예시와 같이 2로 설정할 경우 두 개의 작업이 병렬적으로 실행됨

◦ Rank 0 작업에 Checkpoint 설정

| <p>checkpoint_dir = './checkpoints' if hvd.rank() == 0 else None</p><p>...</p><p>with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,</p><p>hooks=hooks,</p><p>config=config) as mon_sess:</p> |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |

※ Checkpoint 저장 및 불러오는 작업은 하나의 프로세스에서 수행되어야 하므로 rank 0번에 설정함
